{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f87569-1bb6-408f-9457-3cf7333a82d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Amortised Bayesian Inference in Hierarhical Dynamical Systems\n",
    "\n",
    "In this notebook, we examine the embedding of a stochastic autoencoder with a reparametrized variational inference distribution -- a variational autoencoder -- within the settings of dynamical systems for efficient amortised inference of parameters and unobserved states. Initially, we exploit a generative process to capture the uncertainty within the model and, concomitantly, instantiate an inferential procedure to delineate the aleatory uncertainty within the measurements. Subsequently, we endow the inference distribution with a mean-field approximation and further design a neural network to estimate its parameters, which amortizes the computations through the sharing of statistical strength between the instances in the data set. \n",
    "\n",
    "We start, however, with an exposition of the model's architecture; a reasonably self-contained approach is contained in the [slides](./slides). With this objective, notice that, in a hierarchical dynamical system, there are multiple species interacting with distinct environments; these environments, moreover, are stratifiable in distinct (and, as we will verify, compositional) groups, which, then, characterize a population. Thus, each evironments enforms a parametrizable dynamical system; nevertheless, the parameters may, or may not, be shared within the same group or between distinct population. Henceforth, we will identify its parameters as *species*, whereas its distinct instantiations in different branchs of the hierarchy will be characterized as *components*; equivalently, a component is an instance of a species in a prespecified environment. \n",
    "\n",
    "Crucially, in a Bayesian framework, the postulation of a parameter space is equivalent to the identification of a latent space in which the data is properly, although lossy, encoded; hence, we write henceforth $\\mathbf{Z}$ for the model's parameters, which are compartimentalized as \n",
    "\n",
    "\\begin{equation*} \n",
    "(\\mathbf{z}_{I}, \\mathbf{z}_{G}, \\mathbf{z}_{P}) \\in \\mathbf{Z}, \n",
    "\\end{equation*} \n",
    "\n",
    "for the individual, $\\mathbf{z}_{I}$, collective, $\\mathbf{z}_{G}$, and populational $\\mathbf{z}_{P}$, attributes. In these settings, we generative process is as follows. In an initial moment, a latent variable is sampled from an (unknown) distribution, inducing particular strucutral boundaries for the dynamical system, whose realization is subjected to an observer and a noise process, culminating in the current observation. Explicitly, the succeeding algorithm identifies our generative process. \n",
    "\n",
    "+ $\\mathbf{z} \\sim \\pi(\\mathbf{z})$, \n",
    "+ $\\dot{\\mathbf{x}} = \\mathbf{f}(\\mathbf{x}, \\mathbf{z})$, \n",
    "+ $\\mathbf{X} = \\textrm{Simulate}(\\mathbf{f}, \\mathbf{X}_{o})$ ($\\mathbf{X}_{o}$ equals the initial state of the system), \n",
    "+ $M = \\psi(\\mathbf{X})$, the observer process, $\\Sigma = \\rho(\\mathbf{X}, \\mathbf{z})$, the noise process,  \n",
    "+ $\\mathbf{Y} \\sim \\pi(\\mathbf{Y} | M, \\Sigma)$; this comprises the observed data. \n",
    "\n",
    "Importantly, this model accounts concomitantly for white-box, in which a reasonable dynamical system $\\mathbf{f}$ is prespecified by a human, and black-box, with the indexation of the model by a finite-dimensional parameter $\\theta$, $\\mathbf{f}_{\\theta}$, and the succeeding inference on $\\theta$ (jointly with $\\mathbf{z}$), typically with a neural network. The noisy mappings, $\\psi $ and $\\rho$, in contrast, capture the partial observability constraints for this endeavor. Thus, this model is designed for inference on both *highly nonlinear* and *partially observable* dynamical systems, bestowing its amenability to multiple circumstances. \n",
    "\n",
    "Moreover, the generative process induces, by Bayes' rule, a posterior distribution on $\\mathbf{Z}$; precisely, \n",
    "\n",
    "\\begin{equation*} \n",
    "\\pi(\\mathbf{Z} | \\mathbf{Y}) \\propto f(\\mathbf{Y} | \\mathbf{Z}) \\pi(\\mathbf{Z}), \n",
    "\\end{equation*} \n",
    "\n",
    "in which $f(\\mathbf{Y} | \\mathbf{Z})$ corresponds to the likelihood function underlying the mapping from the latent space, $\\mathbf{Z}$, to the samples, $\\mathbf{X}$. Nonetheless, this posterior distribution is in general analytically and computationally intractable; thus, we resort to the variational inference framework through a mean-field approximation and regard the inference as an optimization of a divergence measure between the variational approximation and the model's posterior distribution. More explicitly, we let \n",
    "\n",
    "\\begin{equation*} \n",
    "\\mathcal{Q} = \\{q \\colon \\mathbf{Z} \\rightarrow \\mathbb{R}_{+} | q(\\mathbf{Z}) = q_{\\psi_{I}} (\\mathbf{z}_{I}) q_{\\psi_{G}} (\\mathbf{z}_{G}) q_{\\psi_{P}} (\\mathbf{z}_{P})\\}, \n",
    "\\end{equation*}\n",
    "\n",
    "with $\\psi_{I}$, $\\psi_{G}$ and $\\psi_{P}$ as the variational parameters; nextly, $\\psi = (\\psi_{I}, \\psi_{G}, \\psi_{P})$. Then, we factor the data marginal log-likelihood as \n",
    "\n",
    "\\begin{equation*} \n",
    "\\log p(\\mathbf{Y}) = KL(q(\\cdot) || \\pi( \\cdot | \\mathbf{Y})) + ELBO (q(\\cdot), \\pi(\\cdot | \\mathbf{Y}))\n",
    "\\end{equation*} \n",
    " \n",
    "(we write $KL$ for the Kullback-Leibler divergence; $ELBO$, in contrast, equals the *evidence lower bound*) and subsequently tackle the optimization \n",
    "\n",
    "\\begin{equation*} \n",
    "(\\hat{\\psi_{I}}, \\hat{\\psi_{G}}, \\hat{\\psi_{P}}) = \\textrm{argmin} \\ ELBO(q(\\cdot) | \\pi(\\cdot | \\mathbf{Y})).  \n",
    "\\end{equation*} \n",
    "\n",
    "Circumstantially, we emphasize that, although we could compute, for each instance $\\mathbf{Y}$ in the data set, an optimal parameter $\\psi(\\mathbf{Y})$ to attain the tighest evidence lower bound, this approach would not scale to massive data settings. Hence, we train a neural network [1] that estimates, for each observation, the optimal variational parameters; this approach, in which we share the data's statistical strength through a parametrized estimator, is called *amortized inference*. Particularly, the coupling between a reparametrized variational distribution with a stochastic variational inference characterizes the *variational autoencoders* framework. \n",
    "\n",
    "Alas, this description of the variational autoencoder architecture does not (explicitly) incorporate the hierarchical structure within the dynamical model. Nevertheless, a sensible data model could rectify this -- and it would not require further disruptions in the model's design. In this sense, we expose in the following a mathematical structure for the data which, on the one hand, is amenable to standard statistical approachs designed for relational databases and, on the other hand, is compatible with the *zero-shot learning* environment, in which the model is not constrained to the compartimentalization of the training data -- it consistently estimate the parameters for individuals equipped with previously unseen categorical attributes. \n",
    "\n",
    "In more detail, *each* datum equals a $M \\times T$ matrix, in which $M$ corresponds to the quantity of (observed) states in $T$ different moments; a data set, then, comprises a finite collection of matrices, \n",
    "\n",
    "\\begin{equation*} \n",
    "\\{\\mathbf{Y}^{(n)} \\in \\mathbb{R}^{M \\times T} \\colon n \\in \\{1, \\dots, N\\}\\}, \n",
    "\\end{equation*} \n",
    "\n",
    "with $N$ as data's length. Alternatively, we could exploit a scenario whose temporal ranges are different for each instance; the requirement consists in the design of an appropriate architecture for the amortized inference algorithm, which we will not examine. Furthermore, we attach to each $\\mathbf{Y}^{(n)}$ a *group* $\\mathbf{g}^{(n)}$, which summarizes the hierarchical structure within the dynamical system. Strucutrally, each group is identified as a composition of one-hot encoded shared components; thus, we are *compositionally stratifying the data*. Symbolically, suppose there are $S$ shared components and that each component $s$ attains $K_{s}$ distinct values; thus, we write \n",
    "\n",
    "\\begin{equation*} \n",
    "\\mathbf{g}^{(n)} = \\begin{bmatrix} \\mathbf{c}_{1}^{(n)}, \\dots, \\mathbf{c}_{S}^{(n)} \\end{bmatrix}, \n",
    "\\end{equation*} \n",
    "\n",
    "with $\\mathbf{c}_{s}^{(n)} \\in \\mathbb{R}^{K_{s}}$ as a one-hot encoding vector -- it is a component of $\\mathbb{R}^{K_{s}}$'s canonical basis. As an example, suppose that the component $\\mathbf{c}_{s}$ is parametrized through a finite-dimensional parameter $\\theta_{s} \\in \\mathbb{R}^{K_{s}}$; its instantiation, $\\mathbf{c}_{s}^{(n)}$, thus, would be parametrized with \n",
    "\n",
    "\\begin{equation*} \n",
    "(\\mathbf{c}_{s}^{(n)})^{T} \\theta_{s}. \n",
    "\\end{equation*} \n",
    "\n",
    "In these episodes, we enable the model to estimate the behavior of an individual embedded with *any* composition of groups -- including those which are not contemplated in the training data; this attribute is called *zero-shot* learning. \n",
    "\n",
    "Alternatively, as Geoffrey Roeder appropriately writes, this data model incorporates concomitantly *repeated observations of groups* and *group stratification by composition*. Heuristically, this is equivalent to training a model which aims to capture the structural information within the hierarchically modelled dynamical system. Effectively, this entails the sensible introduction of the prior information within the inferential framework, which is crucial in high-dimensional settings due to the exponential increase in the data's sparsity. \n",
    "\n",
    "[1] The network's architecture is intricate, and its design is not crucial for this notebook's purpose; we do notice that the authors use a importance-weighted autoencoder with a doubly reparemetrized gradient estimators to unbiasedly estimate the parameters' gradient for the network's optimizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6ba846-132f-4726-92b8-d7d24af5893a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example: estimate the protein concentration in cultures \n",
    "\n",
    "In this section, we will endeavor in the estimation of the protein's concentration in distinct culturues; these proteins are generated by genetically modified organisms and, thus, this inference is appropriate to ascertain that the genetic operation did culminate, with a reasonable uncertainty, in the expected cells' behavior. Importantly, this scenario induces, through the laws of chemical kinectics, a highly nonlinear dynamical system, which is exploited as a white-box model that supports the variational autoencoder, and partially observable scenario, as the quantities we objective to measure are compositionally, rather than independently, observed. Moreover, these settings are endowed with an hierarchical structure, as the different cultures are clustered through specific attributes which are controled by the chemist and, correlatively, these attributes are . \n",
    "\n",
    "# Clone the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df4d4fbd-09e1-47df-a8e6-500ed9badd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import os \n",
    "import sys \n",
    "from IPython.display import display, clear_output \n",
    "module = \"hds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f007d6e0-f2ca-46ea-814d-c18c83fb206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(module):\n",
    "    !git clone https://github.com/tiagodsilva/$module \n",
    "    !mv $module/data . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03170691-5d00-4170-b33f-098c813c1061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages; alternativaly, install the Conda environment \n",
    "# and access the Jupyter Notebook therein \n",
    "cmd = f\"pip install -r {module}/requirements.txt\"\n",
    "!{cmd} \n",
    "clear_output() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ad01f4d-a41f-4e87-82f9-29dcf84c77a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload \n",
    "import numpy as np \n",
    "import torch \n",
    "import yaml \n",
    "sys.path.append(module) \n",
    "from vihds.config import Config, Trainer \n",
    "from vihds.datasets import build_datasets \n",
    "from vihds.parameters import Parameters \n",
    "from vihds.training import Training \n",
    "from vihds.xval import XvalMerge \n",
    "from vihds.vae import build_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "252c6a79-b7ae-4133-87cb-bfbd5d942121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users' parameters \n",
    "specs = f\"{module}/specs/dr_constant_icml.yaml\" \n",
    "experiment = \"EXAMPLE\" \n",
    "seed = 42             # The RNG seed\n",
    "epochs = 1            # Training epochs\n",
    "test_epoch = 20       # Test epochs\n",
    "plot_epoch = 100      # Plot epochs\n",
    "train_samples = 20    # Training samples (per datapoint)\n",
    "test_samples = 20     # Testing samples (per datapoint) \n",
    "dreg = True           # DReG estimator \n",
    "precision_hidden_layers = None      # Quantity of hidden layers\n",
    "use_gpu = torch.cuda.is_available() # Use GPU \n",
    "folds = 4                           # Cross-validation folds \n",
    "# Attributes to evauate the models' accuracy \n",
    "heldout = None         # A heldout device (as R33S32_Y81C76) \n",
    "split = 1              # Split for cross-validation in heldout \n",
    "figures = True         # Whether to draw figures \n",
    "verbose = True         # Increase the volume in stdout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee6ec9db-6b19-47db-ad37-3ed022d194f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "  conditions:\n",
      "  - C6\n",
      "  - C12\n",
      "  default_devices:\n",
      "    aR: 0\n",
      "    aS: 0\n",
      "  devices:\n",
      "  - Pcat_Y81C76\n",
      "  - RS100S32_Y81C76\n",
      "  - RS100S34_Y81C76\n",
      "  - R33S32_Y81C76\n",
      "  - R33S34_Y81C76\n",
      "  - R33S175_Y81C76\n",
      "  files:\n",
      "  - proc140916.csv\n",
      "  - proc140930.csv\n",
      "  - proc141006.csv\n",
      "  - proc141021.csv\n",
      "  - proc141023.csv\n",
      "  - proc141028.csv\n",
      "  groups:\n",
      "    aR:\n",
      "    - 0\n",
      "    - 1\n",
      "    - 1\n",
      "    - 2\n",
      "    - 2\n",
      "    - 2\n",
      "    aS:\n",
      "    - 0\n",
      "    - 1\n",
      "    - 2\n",
      "    - 1\n",
      "    - 2\n",
      "    - 3\n",
      "  pretty_devices:\n",
      "  - Pcat-Pcat\n",
      "  - R100-S32\n",
      "  - R100-S34\n",
      "  - R33-S32\n",
      "  - R33-S34\n",
      "  - R33-S175\n",
      "  separate_conditions: true\n",
      "  signals:\n",
      "  - OD\n",
      "  - mRFP1\n",
      "  - EYFP\n",
      "  - ECFP\n",
      "model: dr_constant\n",
      "params:\n",
      "  constant:\n",
      "    init_cfp: 0.0\n",
      "    init_lasR: 0.0\n",
      "    init_luxR: 0.0\n",
      "    init_rfp: 0.0\n",
      "    init_x: 0.002\n",
      "    init_yfp: 0.0\n",
      "  global:\n",
      "    KGR_76:\n",
      "      distribution: LogNormal\n",
      "      mu: 2.0\n",
      "      sigma: 3.0\n",
      "    KGR_81:\n",
      "      distribution: LogNormal\n",
      "      mu: -2.0\n",
      "      sigma: 3.0\n",
      "    KGS_76:\n",
      "      distribution: LogNormal\n",
      "      mu: -2.0\n",
      "      sigma: 3.0\n",
      "    KGS_81:\n",
      "      distribution: LogNormal\n",
      "      mu: 2.0\n",
      "      sigma: 3.0\n",
      "    KR12:\n",
      "      distribution: LogNormal\n",
      "      mu: -12.0\n",
      "      sigma: 3.0\n",
      "    KR6:\n",
      "      distribution: LogNormal\n",
      "      mu: -6.0\n",
      "      sigma: 3.0\n",
      "    KS12:\n",
      "      distribution: LogNormal\n",
      "      mu: -6.0\n",
      "      sigma: 3.0\n",
      "    KS6:\n",
      "      distribution: LogNormal\n",
      "      mu: -12.0\n",
      "      sigma: 3.0\n",
      "    a480:\n",
      "      distribution: auto_prec\n",
      "    a530:\n",
      "      distribution: auto_prec\n",
      "    aCFP:\n",
      "      distribution: LogNormal\n",
      "      mu: 0.0\n",
      "      sigma: 2.0\n",
      "    aYFP:\n",
      "      distribution: LogNormal\n",
      "      mu: 0.0\n",
      "      sigma: 2.0\n",
      "    dR:\n",
      "      distribution: LogNormal\n",
      "      mu: -2.0\n",
      "      sigma: 1.0\n",
      "    dS:\n",
      "      distribution: LogNormal\n",
      "      mu: -2.0\n",
      "      sigma: 1.0\n",
      "    dcfp:\n",
      "      distribution: dfp_prec\n",
      "    drfp:\n",
      "      distribution: dfp_prec\n",
      "    dyfp:\n",
      "      distribution: dfp_prec\n",
      "    e76:\n",
      "      distribution: LogNormal\n",
      "      mu: -3.0\n",
      "      sigma: 1.0\n",
      "    e81:\n",
      "      distribution: LogNormal\n",
      "      mu: -3.0\n",
      "      sigma: 1.0\n",
      "    nR:\n",
      "      distribution: LogNormal\n",
      "      mu: 0.0\n",
      "      sigma: 0.25\n",
      "    nS:\n",
      "      distribution: LogNormal\n",
      "      mu: 0.0\n",
      "      sigma: 0.25\n",
      "    prec_cfp:\n",
      "      distribution: data_prec\n",
      "    prec_rfp:\n",
      "      distribution: data_prec\n",
      "    prec_x:\n",
      "      distribution: data_prec\n",
      "    prec_yfp:\n",
      "      distribution: data_prec\n",
      "  global_conditioned:\n",
      "    conditioning:\n",
      "      devices: true\n",
      "      treatments: false\n",
      "  learning_boundaries:\n",
      "  - 250\n",
      "  - 1000\n",
      "  learning_gamma: 0.2\n",
      "  learning_rate: 0.01\n",
      "  local:\n",
      "    K:\n",
      "      distribution: LogNormal\n",
      "      mu: 1.0\n",
      "      prec: 2.0\n",
      "    conditioning:\n",
      "      devices: true\n",
      "      treatments: false\n",
      "    r:\n",
      "      distribution: LogNormal\n",
      "      mu: 0.0\n",
      "      sigma: 0.25\n",
      "    rc:\n",
      "      distribution: LogNormal\n",
      "      mu: 0.0\n",
      "      sigma: 2.0\n",
      "    tlag:\n",
      "      distribution: LogNormal\n",
      "      mu: 0.0\n",
      "      prec: 2.0\n",
      "  shared:\n",
      "    auto_prec:\n",
      "      distribution: LogNormal\n",
      "      mu: -5.0\n",
      "      sigma: 2.0\n",
      "    data_prec:\n",
      "      distribution: LogNormal\n",
      "      mu: 8.0\n",
      "      sigma: 2.0\n",
      "    dfp_prec:\n",
      "      distribution: LogNormal\n",
      "      mu: -2.0\n",
      "      sigma: 1.5\n",
      "  solver: midpoint\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the models' specifications\n",
    "model_specs = yaml.load(open(specs, \"r\"), Loader=yaml.loader.SafeLoader) \n",
    "print(yaml.dump(model_specs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53794374-baaa-4215-9622-ede89b41dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace(object): \n",
    "    def __init__(self, **kwargs): \n",
    "        for key, val in kwargs.items(): \n",
    "            self.__dict__[key] = val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edcd985b-55ad-4a4e-a29f-8fb151a87c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace( \n",
    "    yaml=specs, \n",
    "    experiment=experiment,\n",
    "    seed=seed, \n",
    "    epochs=epochs, \n",
    "    test_epoch=test_epoch, \n",
    "    plot_epoch=plot_epoch, \n",
    "    train_samples=train_samples,\n",
    "    test_samples=test_samples,\n",
    "    dreg=dreg,\n",
    "    precision_hidden_layers=precision_hidden_layers,\n",
    "    gpu=torch.cuda.current_device() if use_gpu else \"cpu\", \n",
    "    folds=folds, \n",
    "    heldout=heldout, \n",
    "    split=split, \n",
    "    figures=figures, \n",
    "    verbose=verbose\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98cfc00b-96d1-4053-9169-53eb193263a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_on_split(args: Namespace, \n",
    "                 settings: Namespace, \n",
    "                 split: bool=None): \n",
    "    \"\"\"\n",
    "    Execute a training-testing split. \n",
    "    \"\"\"\n",
    "    data = build_datasets(args, settings) \n",
    "    parameters = Parameters(settings.params) \n",
    "    model = build_model(args, settings, data, parameters) \n",
    "    training = Training(args, settings, data, parameters, model) \n",
    "    # Return the data and the evaluations for the current epoch\n",
    "    return data, training.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5695590e-d2d1-49ae-b4a6-5adfc402d169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing command-line arguments\n",
      "- <__main__.Namespace object at 0x7fc35dffa0d0>\n",
      "- Setting test_epoch to 1\n",
      "- Setting plot_epoch to 1\n",
      "- Setting: np.random.seed(42)\n",
      "- Setting: torch.manual_seed(42)\n",
      "- GPU mode computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hds/vihds/datasets.py:137: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  times_arr = np.asarray(times_list)\n",
      "hds/vihds/datasets.py:138: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  obs_arr = np.asarray(observations_list)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m settings \u001b[38;5;241m=\u001b[39m Config(args) \n\u001b[1;32m      2\u001b[0m settings\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m Trainer(args, add_timestamp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[0;32m----> 3\u001b[0m data_pair, val_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_on_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (val_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m settings\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \n\u001b[1;32m      6\u001b[0m     xval_merge \u001b[38;5;241m=\u001b[39m XvalMerge(args, settings) \n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mrun_on_split\u001b[0;34m(args, settings, split)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_on_split\u001b[39m(args: Namespace, \n\u001b[1;32m      2\u001b[0m                  settings: Namespace, \n\u001b[1;32m      3\u001b[0m                  split: \u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m): \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    Execute a training-testing split. \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      8\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m Parameters(settings\u001b[38;5;241m.\u001b[39mparams) \n\u001b[1;32m      9\u001b[0m     model \u001b[38;5;241m=\u001b[39m build_model(args, settings, data, parameters) \n",
      "File \u001b[0;32m~/stuff/SystemsDynamics/vihds/hds/notebooks/hds/vihds/datasets.py:185\u001b[0m, in \u001b[0;36mbuild_datasets\u001b[0;34m(args, config)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_settings\u001b[38;5;241m.\u001b[39mmerge:\n\u001b[1;32m    184\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m TimeSeriesDataset(data_settings, config\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m--> 185\u001b[0m     \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_multiple_merge\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# datasets.append(dataset)\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# raise NotImplementedError('TODO: Enable non-merged time-series data')\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     datasets \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/stuff/SystemsDynamics/vihds/hds/notebooks/hds/vihds/datasets.py:107\u001b[0m, in \u001b[0;36mTimeSeriesDataset.init_multiple_merge\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m times, observations \u001b[38;5;241m=\u001b[39m merge_observations(times_list, observations_list)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# filter_nonempty = [datasets[i] for i in range(len(datasets)) if datasets[i] is not None]\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# dataset = reduce(merge_files, filter_nonempty)\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/stuff/SystemsDynamics/vihds/hds/notebooks/hds/vihds/datasets.py:85\u001b[0m, in \u001b[0;36mTimeSeriesDataset._preprocess\u001b[0;34m(self, devices, inputs, times, observations)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevices \u001b[38;5;241m=\u001b[39m devices\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# One-hot encoding of device IDs for each of the L observations: (np.ndarray; L)\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev_1hot \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_cassettes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_settings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Transformed values of C input conditions, for each of the L observations: (np.ndarray; L x C)\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m inputs))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "settings = Config(args) \n",
    "settings.trainer = Trainer(args, add_timestamp=True) \n",
    "data_pair, val_results = run_on_split(args, settings) \n",
    "\n",
    "if (val_results is not None) and settings.trainer is not None: \n",
    "    xval_merge = XvalMerge(args, settings) \n",
    "    xval_merge.add(1, data_pair, val_results) \n",
    "    xval_merge.finalize() \n",
    "    xval_merge.save() \n",
    "    xval_merge.mark_completed(args.experiment) \n",
    "    if args.figures: \n",
    "        xval_merge.make_writer() \n",
    "        xval_merge.make_images() \n",
    "        xval_merge.close_writer() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
