{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f87569-1bb6-408f-9457-3cf7333a82d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Amortised Bayesian Inference in Hierarhical Dynamical Systems\n",
    "\n",
    "In this notebook, we examine the embedding of a stochastic autoencoder with a reparametrized variational inference distribution -- a variational autoencoder -- within the settings of dynamical systems for efficient amortised inference of parameters and unobserved states. Initially, we exploit a generative process to capture the uncertainty within the model and, concomitantly, instantiate an inferential procedure to delineate the aleatory uncertainty within the measurements. Subsequently, we endow the inference distribution with a mean-field approximation and further design a neural network to estimate its parameters, which amortizes the computations through the sharing of statistical strength between the instances in the data set. \n",
    "\n",
    "We start, however, with an exposition of the model's architecture; a reasonably self-contained approach is contained in the [slides](./slides). With this objective, notice that, in a hierarchical dynamical system, there are multiple species interacting with distinct environments; these environments, moreover, are stratifiable in distinct (and, as we will verify, compositional) groups, which, then, characterize a population. Thus, each evironments enforms a parametrizable dynamical system; nevertheless, the parameters may, or may not, be shared within the same group or between distinct population. Henceforth, we will identify its parameters as *species*, whereas its distinct instantiations in different branchs of the hierarchy will be characterized as *components*; equivalently, a component is an instance of a species in a prespecified environment. \n",
    "\n",
    "Crucially, in a Bayesian framework, the postulation of a parameter space is equivalent to the identification of a latent space in which the data is properly, although lossy, encoded; hence, we write henceforth $\\mathbf{Z}$ for the model's parameters, which are compartimentalized as \n",
    "\n",
    "\\begin{equation*} \n",
    "(\\mathbf{z}_{I}, \\mathbf{z}_{G}, \\mathbf{z}_{P}) \\in \\mathbf{Z}, \n",
    "\\end{equation*} \n",
    "\n",
    "for the individual, $\\mathbf{z}_{I}$, collective, $\\mathbf{z}_{G}$, and populational $\\mathbf{z}_{P}$, attributes. In these settings, we generative process is as follows. In an initial moment, a latent variable is sampled from an (unknown) distribution, inducing particular strucutral boundaries for the dynamical system, whose realization is subjected to an observer and a noise process, culminating in the current observation. Explicitly, the succeeding algorithm identifies our generative process. \n",
    "\n",
    "+ $\\mathbf{z} \\sim \\pi(\\mathbf{z})$, \n",
    "+ $\\dot{\\mathbf{x}} = \\mathbf{f}(\\mathbf{x}, \\mathbf{z})$, \n",
    "+ $\\mathbf{X} = \\textrm{Simulate}(\\mathbf{f}, \\mathbf{X}_{o})$ ($\\mathbf{X}_{o}$ equals the initial state of the system), \n",
    "+ $M = \\psi(\\mathbf{X})$, the observer process, $\\Sigma = \\rho(\\mathbf{X}, \\mathbf{z})$, the noise process,  \n",
    "+ $\\mathbf{Y} \\sim \\pi(\\mathbf{Y} | M, \\Sigma)$; this comprises the observed data. \n",
    "\n",
    "Importantly, this model accounts concomitantly for white-box, in which a reasonable dynamical system $\\mathbf{f}$ is prespecified by a human, and black-box, with the indexation of the model by a finite-dimensional parameter $\\theta$, $\\mathbf{f}_{\\theta}$, and the succeeding inference on $\\theta$ (jointly with $\\mathbf{z}$), typically with a neural network. The noisy mappings, $\\psi $ and $\\rho$, in contrast, capture the partial observability constraints for this endeavor. Thus, this model is designed for inference on both *highly nonlinear* and *partially observable* dynamical systems, bestowing its amenability to multiple circumstances. \n",
    "\n",
    "Moreover, the generative process induces, by Bayes' rule, a posterior distribution on $\\mathbf{Z}$; precisely, \n",
    "\n",
    "\\begin{equation*} \n",
    "\\pi(\\mathbf{Z} | \\mathbf{Y}) \\propto f(\\mathbf{Y} | \\mathbf{Z}) \\pi(\\mathbf{Z}), \n",
    "\\end{equation*} \n",
    "\n",
    "in which $f(\\mathbf{Y} | \\mathbf{Z})$ corresponds to the likelihood function underlying the mapping from the latent space, $\\mathbf{Z}$, to the samples, $\\mathbf{X}$. Nonetheless, this posterior distribution is in general analytically and computationally intractable; thus, we resort to the variational inference framework through a mean-field approximation and regard the inference as an optimization of a divergence measure between the variational approximation and the model's posterior distribution. More explicitly, we let \n",
    "\n",
    "\\begin{equation*} \n",
    "\\mathcal{Q} = \\{q \\colon \\mathbf{Z} \\rightarrow \\mathbb{R}_{+} | q(\\mathbf{Z}) = q_{\\psi_{I}} (\\mathbf{z}_{I}) q_{\\psi_{G}} (\\mathbf{z}_{G}) q_{\\psi_{P}} (\\mathbf{z}_{P})\\}, \n",
    "\\end{equation*}\n",
    "\n",
    "with $\\psi_{I}$, $\\psi_{G}$ and $\\psi_{P}$ as the variational parameters; nextly, $\\psi = (\\psi_{I}, \\psi_{G}, \\psi_{P})$. Then, we factor the data marginal log-likelihood as \n",
    "\n",
    "\\begin{equation*} \n",
    "\\log p(\\mathbf{Y}) = KL(q(\\cdot) || \\pi( \\cdot | \\mathbf{Y})) + ELBO (q(\\cdot), \\pi(\\cdot | \\mathbf{Y}))\n",
    "\\end{equation*} \n",
    " \n",
    "(we write $KL$ for the Kullback-Leibler divergence; $ELBO$, in contrast, equals the *evidence lower bound*) and subsequently tackle the optimization \n",
    "\n",
    "\\begin{equation*} \n",
    "(\\hat{\\psi_{I}}, \\hat{\\psi_{G}}, \\hat{\\psi_{P}}) = \\textrm{argmin} \\ ELBO(q(\\cdot) | \\pi(\\cdot | \\mathbf{Y})).  \n",
    "\\end{equation*} \n",
    "\n",
    "Circumstantially, we emphasize that, although we could compute, for each instance $\\mathbf{Y}$ in the data set, an optimal parameter $\\psi(\\mathbf{Y})$ to attain the tighest evidence lower bound, this approach would not scale to massive data settings. Hence, we train a neural network [1] that estimates, for each observation, the optimal variational parameters; this approach, in which we share the data's statistical strength through a parametrized estimator, is called *amortized inference*. Particularly, the coupling between a reparametrized variational distribution with a stochastic variational inference characterizes the *variational autoencoders* framework. \n",
    "\n",
    "[1] The network's architecture is intricate, and its design is not crucial for this notebook's purpose; we do notice that the authors use a importance-weighted autoencoder with a doubly reparemetrized gradient estimators to unbiasedly estimate the parameters' gradient for the network's optimizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6ba846-132f-4726-92b8-d7d24af5893a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clone the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4d4fbd-09e1-47df-a8e6-500ed9badd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import os \n",
    "import sys \n",
    "from IPython.display import display, clear_output \n",
    "module = \"hds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f007d6e0-f2ca-46ea-814d-c18c83fb206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(module):\n",
    "    !git clone https://github.com/tiagodsilva/$module \n",
    "    !mv $module/data . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03170691-5d00-4170-b33f-098c813c1061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages; alternativaly, install the Conda's environment\n",
    "cmd = f\"pip install -r {module}/requirements.txt\"\n",
    "status = os.system(cmd) \n",
    "if status == 0: \n",
    "    clear_output() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ad01f4d-a41f-4e87-82f9-29dcf84c77a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload \n",
    "import numpy as np \n",
    "import torch \n",
    "import yaml \n",
    "sys.path.append(module) \n",
    "from vihds.config import Config, Trainer \n",
    "from vihds.datasets import build_datasets \n",
    "from vihds.parameters import Parameters \n",
    "from vihds.training import Training \n",
    "from vihds.xval import XvalMerge \n",
    "from vihds.vae import build_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "252c6a79-b7ae-4133-87cb-bfbd5d942121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users' parameters \n",
    "specs = f\"{module}/specs/dr_constant_icml.yaml\" \n",
    "experiment = \"EXAMPLE\" \n",
    "seed = 42             # The RNG seed\n",
    "epochs = 1            # Training epochs\n",
    "test_epoch = 20       # Test epochs\n",
    "plot_epoch = 100      # Plot epochs\n",
    "train_samples = 20    # Training samples (per datapoint)\n",
    "test_samples = 20     # Testing samples (per datapoint) \n",
    "dreg = True           # DReG estimator \n",
    "precision_hidden_layers = None      # Quantity of hidden layers\n",
    "use_gpu = torch.cuda.is_available() # Use GPU \n",
    "folds = 4                           # Cross-validation folds \n",
    "# Attributes to evauate the models' accuracy \n",
    "heldout = None         # A heldout device (as R33S32_Y81C76) \n",
    "split = 1              # Split for cross-validation in heldout \n",
    "figures = True         # Whether to draw figures \n",
    "verbose = True         # Increase the volume in stdout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee6ec9db-6b19-47db-ad37-3ed022d194f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "  conditions:\n",
      "  - C6\n",
      "  - C12\n",
      "  default_devices:\n",
      "    aR: 0\n",
      "    aS: 0\n",
      "  devices:\n",
      "  - Pcat_Y81C76\n",
      "  - RS100S32_Y81C76\n",
      "  - RS100S34_Y81C76\n",
      "  - R33S32_Y81C76\n",
      "  - R33S34_Y81C76\n",
      "  - R33S175_Y81C76\n",
      "  files:\n",
      "  - proc140916.csv\n",
      "  - proc140930.csv\n",
      "  - proc141006.csv\n",
      "  - proc141021.csv\n",
      "  - proc141023.csv\n",
      "  - proc141028.csv\n",
      "  groups:\n",
      "    aR:\n",
      "    - 0\n",
      "    - 1\n",
      "    - 1\n",
      "    - 2\n",
      "    - 2\n",
      "    - 2\n",
      "    aS:\n",
      "    - 0\n",
      "    - 1\n",
      "    - 2\n",
      "    - 1\n",
      "    - 2\n",
      "    - 3\n",
      "  pretty_devices:\n",
      "  - Pcat-Pcat\n",
      "  - R100-S32\n",
      "  - R100-S34\n",
      "  - R33-S32\n",
      "  - R33-S34\n",
      "  - R33-S175\n",
      "  separate_conditions: true\n",
      "  signals:\n",
      "  - OD\n",
      "  - mRFP1\n",
      "  - EYFP\n",
      "  - ECFP\n",
      "model: dr_constant\n",
      "params:\n",
      "  constant:\n",
      "    init_cfp: 0.0\n",
      "    init_lasR: 0.0\n",
      "    init_luxR: 0.0\n",
      "    init_rfp: 0.0\n",
      "    init_x: 0.002\n",
      "    init_yfp: 0.0\n",
      "  global:\n",
      "    KGR_76:\n",
      "      distribution: LogNormal\n",
      "      mu: 2.0\n",
      "      sigma: 3.0\n",
      "    KGR_81:\n",
      "      distribution: LogNormal\n",
      "      mu: -2.0\n",
      "      sigma: 3.0\n",
      "    KGS_76:\n",
      "      distribution: LogNormal\n",
      "      mu: -2.0\n",
      "      sigma: 3.0\n",
      "    KGS_81:\n",
      "      distribution: LogNormal\n",
      "      mu: 2.0\n",
      "      sigma: 3.0\n",
      "    KR12:\n",
      "      distribution: LogNormal\n",
      "      mu: -12.0\n",
      "      sigma: 3.0\n",
      "    KR6:\n",
      "      distribution: LogNormal\n",
      "      mu: -6.0\n",
      "      sigma: 3.0\n",
      "    KS12:\n",
      "      distribution: LogNormal\n",
      "      mu: -6.0\n",
      "      sigma: 3.0\n",
      "    KS6:\n",
      "      distribution: LogNormal\n",
      "      mu: -12.0\n",
      "      sigma: 3.0\n",
      "    a480:\n",
      "      distribution: auto_prec\n",
      "    a530:\n",
      "      distribution: auto_prec\n",
      "    aCFP:\n",
      "      distribution: LogNormal\n",
      "      mu: 0.0\n",
      "      sigma: 2.0\n",
      "    aYFP:\n",
      "      distribution: LogNormal\n",
      "      mu: 0.0\n",
      "      sigma: 2.0\n",
      "    dR:\n",
      "      distribution: LogNormal\n",
      "      mu: -2.0\n",
      "      sigma: 1.0\n",
      "    dS:\n",
      "      distribution: LogNormal\n",
      "      mu: -2.0\n",
      "      sigma: 1.0\n",
      "    dcfp:\n",
      "      distribution: dfp_prec\n",
      "    drfp:\n",
      "      distribution: dfp_prec\n",
      "    dyfp:\n",
      "      distribution: dfp_prec\n",
      "    e76:\n",
      "      distribution: LogNormal\n",
      "      mu: -3.0\n",
      "      sigma: 1.0\n",
      "    e81:\n",
      "      distribution: LogNormal\n",
      "      mu: -3.0\n",
      "      sigma: 1.0\n",
      "    nR:\n",
      "      distribution: LogNormal\n",
      "      mu: 0.0\n",
      "      sigma: 0.25\n",
      "    nS:\n",
      "      distribution: LogNormal\n",
      "      mu: 0.0\n",
      "      sigma: 0.25\n",
      "    prec_cfp:\n",
      "      distribution: data_prec\n",
      "    prec_rfp:\n",
      "      distribution: data_prec\n",
      "    prec_x:\n",
      "      distribution: data_prec\n",
      "    prec_yfp:\n",
      "      distribution: data_prec\n",
      "  global_conditioned:\n",
      "    conditioning:\n",
      "      devices: true\n",
      "      treatments: false\n",
      "  learning_boundaries:\n",
      "  - 250\n",
      "  - 1000\n",
      "  learning_gamma: 0.2\n",
      "  learning_rate: 0.01\n",
      "  local:\n",
      "    K:\n",
      "      distribution: LogNormal\n",
      "      mu: 1.0\n",
      "      prec: 2.0\n",
      "    conditioning:\n",
      "      devices: true\n",
      "      treatments: false\n",
      "    r:\n",
      "      distribution: LogNormal\n",
      "      mu: 0.0\n",
      "      sigma: 0.25\n",
      "    rc:\n",
      "      distribution: LogNormal\n",
      "      mu: 0.0\n",
      "      sigma: 2.0\n",
      "    tlag:\n",
      "      distribution: LogNormal\n",
      "      mu: 0.0\n",
      "      prec: 2.0\n",
      "  shared:\n",
      "    auto_prec:\n",
      "      distribution: LogNormal\n",
      "      mu: -5.0\n",
      "      sigma: 2.0\n",
      "    data_prec:\n",
      "      distribution: LogNormal\n",
      "      mu: 8.0\n",
      "      sigma: 2.0\n",
      "    dfp_prec:\n",
      "      distribution: LogNormal\n",
      "      mu: -2.0\n",
      "      sigma: 1.5\n",
      "  solver: midpoint\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the models' specifications\n",
    "model_specs = yaml.load(open(specs, \"r\"), \n",
    "                    Loader=yaml.loader.SafeLoader) \n",
    "print(yaml.dump(model_specs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53794374-baaa-4215-9622-ede89b41dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace(object): \n",
    "    def __init__(self, **kwargs): \n",
    "        for key, val in kwargs.items(): \n",
    "            self.__dict__[key] = val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edcd985b-55ad-4a4e-a29f-8fb151a87c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace( \n",
    "    yaml=specs, \n",
    "    experiment=experiment,\n",
    "    seed=seed, \n",
    "    epochs=epochs, \n",
    "    test_epoch=test_epoch, \n",
    "    plot_epoch=plot_epoch, \n",
    "    train_samples=train_samples,\n",
    "    test_samples=test_samples,\n",
    "    dreg=dreg,\n",
    "    precision_hidden_layers=precision_hidden_layers,\n",
    "    gpu=torch.cuda.current_device() if use_gpu else \"cpu\", \n",
    "    folds=folds, \n",
    "    heldout=heldout, \n",
    "    split=split, \n",
    "    figures=figures, \n",
    "    verbose=verbose\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98cfc00b-96d1-4053-9169-53eb193263a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_on_split(args: Namespace, \n",
    "                 settings: Namespace, \n",
    "                 split: bool=None): \n",
    "    \"\"\"\n",
    "    Execute a training-testing split. \n",
    "    \"\"\"\n",
    "    data = build_datasets(args, settings) \n",
    "    parameters = Parameters(settings.params) \n",
    "    model = build_model(args, settings, data, parameters) \n",
    "    training = Training(args, settings, data, parameters, model) \n",
    "    # Return the data and the evaluations for the current epoch\n",
    "    return data, training.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5695590e-d2d1-49ae-b4a6-5adfc402d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args: Namespace): \n",
    "    settings = Config(args) \n",
    "    settings.trainer = Trainer(args, add_timestamp=True) \n",
    "    data_pair, val_results = run_on_split(args, settings) \n",
    "    \n",
    "    if (val_results is not None) and settings.trainer is not None: \n",
    "        xval_merge = XvalMerge(args, settings) \n",
    "        xval_merge.add(1, data_pair, val_results) \n",
    "        xval_merge.finalize() \n",
    "        xval_merge.save() \n",
    "        xval_merge.mark_completed(args.experiment) \n",
    "        if args.figures: \n",
    "            xval_merge.make_writer() \n",
    "            xval_merge.make_images() \n",
    "            xval_merge.close_writer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7e00dde6-3f04-458e-a5ee-a6d4259ef30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing command-line arguments\n",
      "- <__main__.Namespace object at 0x7f9e3d8d68e0>\n",
      "- Setting test_epoch to 1\n",
      "- Setting plot_epoch to 1\n",
      "- Setting: np.random.seed(42)\n",
      "- Setting: torch.manual_seed(42)\n",
      "- GPU mode computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hds/vihds/datasets.py:137: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  times_arr = np.asarray(times_list)\n",
      "hds/vihds/datasets.py:138: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  obs_arr = np.asarray(observations_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising encoder\n",
      "Initialising decoder\n",
      "---------------------------\n",
      "Training: split 1 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%| | 0/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    1 | train (iwae-elbo = -7252.9907, time = 3.17, total = 3.17)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆ| 1/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | val (iwae-elbo = -7554.3672, time = 5.97, total = 5.97)\n",
      "Preparing cross-validation results\n",
      "Saving results to results/EXAMPLE_20220813T222914592234\n",
      "Saving to: results/EXAMPLE_20220813T222914592234\n",
      "Making summary figure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/tiago/anaconda3/envs/viewer/envs/vihds/lib/python3.8/site-packages/numpy/lib/npyio.py:501: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making treatment figure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hds/vihds/plotting.py:255: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"kx\" (-> color='k'). The keyword argument will take precedence.\n",
      "  ax.semilogx(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making species figure\n",
      "Making global parameters figure\n",
      "-  ['prec_x', 'prec_rfp', 'prec_yfp', 'prec_cfp', 'e76', 'e81', 'KGR_76', 'KGR_81', 'KGS_76', 'KGS_81', 'KR6', 'KR12', 'KS6', 'KS12', 'nR', 'nS', 'aYFP', 'aCFP', 'dR', 'dS', 'drfp', 'dyfp', 'dcfp', 'a530', 'a480']\n",
      "Making variable parameters figure\n",
      "-  ['r', 'K', 'tlag', 'rc']\n",
      "Making summary device figures\n",
      "- Pcat-Pcat\n",
      "- R100-S32\n",
      "- R100-S34\n",
      "- R33-S32\n",
      "- R33-S34\n",
      "- R33-S175\n",
      "Making individual device figures\n",
      "- Pcat-Pcat\n",
      "- R100-S32\n",
      "- R100-S34\n",
      "- R33-S32\n",
      "- R33-S34\n",
      "- R33-S175\n"
     ]
    }
   ],
   "source": [
    "train(args) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
